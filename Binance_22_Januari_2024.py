# -*- coding: utf-8 -*-
"""Binance_22 Januari 2024_Coba Kedua

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S8yQZXUJbwXrIjIihrlPhwCj75lf5egT

SUMBER: https://www.kaggle.com/datasets/franoisgeorgesjulien/crypto

DATASET: Crypto Data Hourly Price since 2017 to 2023-10
"""

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM, GRU
from keras.layers import Dropout
from sklearn.preprocessing import MinMaxScaler
from keras.models import load_model
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint
import itertools
import random
import os

from google.colab import drive
drive.mount('/content/drive')

import os
path = '/content/drive/My Drive/Binance_1INCHUSDT_1h/'
os.listdir(path)

import pandas as pd
df = pd.read_csv(path + 'Binance_1INCHUSDT_1h.csv', encoding='utf-8', parse_dates=['Date'])
#df = pd.read_csv('bbc-text.csv', encoding='utf-8')

df['volume'] = df['Volume 1INCH']
df.info()

# Urutkan data berdasarkan kolom tanggal
df= df.sort_values(by='Date')
df.head()

# Show data by picture
df[df['Symbol'] == '1INCHUSDT'].plot(subplots=True, sharex=True, figsize=(10,10))
plt.show()

plt.figure(figsize=(16,8), dpi= 100, facecolor='w', edgecolor='k')

plt.plot(df['Open'], color='red', label = 'Opening Price')
plt.plot(df['Close'], color='green', label = 'Closing Price')
plt.plot(df['Low'], color='black', label = 'Low Price')
plt.plot(df['High'], color='blue', label = 'High Price')
plt.legend(loc='best')

plt.subplots(2, 2, figsize = (20, 10))

ax1 = plt.subplot(2, 2, 1)
plt.plot(df['Open'], color='red')
plt.xlabel('Date')
plt.ylabel('Opening Price')

ax2 = plt.subplot(2, 2, 2)
plt.plot(df['Close'], color='green')
plt.xlabel('Date')
plt.ylabel('Closing Price')

ax3 = plt.subplot(2, 2, 3)
plt.plot(df['Low'], color='black')
plt.xlabel('Date')
plt.ylabel('Low Price')

ax4 = plt.subplot(2, 2, 4)
plt.plot(df['High'], color='blue')
plt.xlabel('Date')
plt.ylabel('High Price')

plt.legend(loc='best')

"""## Data Preprocessing"""

#Check for null values and the statistical measurement
print(df.isna().sum())
print(df.describe())

"""Date, Symbol, Open, High, Low, Close, Volume 1INCH, Volume USTD, tradecount"""

#Get rid of features that has no relevancy and undescribed features
df = df.drop(['Symbol', 'Volume 1INCH', 'Volume USDT', 'tradecount',], axis=1)

#Normalize the volume features
df.Open= (df.Open-df.Open.min()
                     )/(df.Open.max()-df.Open.min())

#Sorting by dates
dates = pd.to_datetime(df.Date)
df = df.drop('Date', axis=1)
df['Date'] = dates

df = df
df_sorted = df.sort_values(by='Date')
df_sorted = df.reset_index()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

#Plot 1INCH price
dates = df_sorted.Date
target_open_price = df_sorted.Open.values

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
ax.plot(dates[:300], target_open_price[:300])
ax.set(xlabel="Date",
       ylabel="(USD Dollar)",
       title="1INCH open price")
plt.setp(ax.get_xticklabels(), rotation=45)
plt.show()

import matplotlib.pyplot as plt

time = df['Date'].values
open = df['Open'].values

plt.figure(figsize=(12, 5))
plt.plot(time, open)
plt.title('1INCH Open Price', fontsize=20)
plt.xlabel('Date')
plt.ylabel('USD')
plt.show()

"""Data Slicing and Splitting"""

#Split timeframe data for train and val data
from sklearn.model_selection import train_test_split
#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state = 300)
X_train, X_val, y_train, y_val = train_test_split(time, open, test_size=0.2, shuffle=False)

print(X_train.shape, X_val.shape)
print(y_train.shape, y_val.shape)

"""Build Tensorflow Model"""

import tensorflow as tf

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)

    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))

    return ds.batch(batch_size).prefetch(1)

train_set = windowed_dataset(y_train, window_size=60, batch_size=100, shuffle_buffer=1000)
val_set   = windowed_dataset(y_val,  window_size=60, batch_size=100, shuffle_buffer=1000)

maeScale = (open.max() - open.min()) * 10/100
print(maeScale)

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('mae')< maeScale and logs.get('val_mae') < maeScale):
            print("\nMAE dan Val MAE telah mencapai nilai < 10% dari data. Training dihentikan.")
            self.model.stop_training = True
callbacks = myCallback()

"""untuk arsitektur model gunakan 2 buah layer LSTM. Ketika menggunakan 2 buah layer LSTM, perhatikan bahwa layer pertama harus memiliki parameter return_sequences yang bernilai True."""

# Model
model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(60, return_sequences=True),
    tf.keras.layers.LSTM(60),
    tf.keras.layers.Dense(30, activation="relu"),
    tf.keras.layers.Dense(10, activation="relu"),
    tf.keras.layers.Dense(1),
    ])

# Menggunakan TimeDistributed untuk memproses setiap waktu dalam sekuen
# model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1)))

# Kompilasi model
optimizer = tf.keras.optimizers.SGD(learning_rate=1.00e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

epoch = 100

history = model.fit(train_set, epochs=epoch, verbose=2, validation_data=val_set, callbacks=[callbacks])

mae_train = history.history['mae']
mae_val = history.history['val_mae']
train_loss = history.history['loss']
val_loss = history.history['val_loss']

epoch = np.arange(1, len(mae_train) + 1)
#epoch = np.arange(46)

plt.plot(epoch, mae_train, 'b')
plt.plot(epoch, mae_val, 'g')
plt.xlabel('epochs')
plt.ylabel('mae')
plt.legend(['mae_train', 'mae_val'])

plt.plot(epoch, train_loss, 'b')
plt.plot(epoch, val_loss, 'g')
plt.xlabel('epochs')
plt.ylabel('mae')
plt.legend(['mae_train', 'mae_val'])

plt.figure(figsize = (12, 4))
plt.subplot(1, 2, 1)
plt.plot(epoch, mae_train,     label='Training MAE')
plt.plot(epoch, mae_val, label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend(loc='lower right')

plt.subplot(1, 2, 2)
plt.plot(epoch, train_loss,     label='Training Loss')
plt.plot(epoch, val_loss, label='Valodation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

plt.show()